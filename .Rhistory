select(3:5, 2) %>%
mutate(Gravida=as.factor(Gravida))
View(boruta_important_data)
index_row_boruta <- sample(1:2,
nrow(boruta_important_data),
replace = T,
prob = c(0.7,0.3))
index_row_boruta <- sample(1:2,
nrow(boruta_important_data),
replace = T,
prob = c(0.7,0.3))
train_data <- boruta_important_data[index_row_boruta==1,]
test_data <- boruta_important_data[index_row_boruta==2,]
# Run random forest to test the data
classifier <- randomForest(Gravida ~ .,
data=train_data,
importance=T, ntree=1000)
classifier
boruta_result <- Boruta(Gravida ~ ., data = boruta_important_data,
doTrace=2, maxRuns=10000)
plot(boruta_result)
# Print summary of Boruta result
print(boruta_result)
# Plot Boruta result
plot(boruta_result, cex.=0.5)
View(boruta_result)
#
boruta_result$ImpHistory
# Data frame for important variables
important_proteins <- as.data.frame (boruta_result$ImpHistory)
View(important_proteins)
important_proteins %>%
pivot_longer(names_to = "Attributes",
values_to = "Importance")
important_proteins %>%
pivot_longer(names_to = "Attributes",
values_to = "Importance",
cols = 1:6)
important_proteins %>%
pivot_longer(names_to = "Attributes",
values_to = "Importance",
cols = 1:6) %>%
ggplot()+
geom_boxplot(aes(Attributes, Importance))
?plot()
?plot
# Plot Boruta result
plot(boruta_result)
# stats on the importance of attributes
attStats(boruta_result, cex=0.5)
# Plot Boruta result
plot(boruta_result, cex=0.5)
classifier
# Print summary of Boruta result
print(boruta_result)
model <- glm(Gravida ~ ., data = boruta_important_data, family = "binomial")
summary(model)
model <- glm(Gravida ~ ., data = boruta_important_data, family = binomial())
summary(model)
# assess if there is interaction between the different proteins
model_interaction <- glm(Gravida ~ PF3D7_0100100_CIDR.2.8 * PF3D7_0533100_DBL5 * PF3D7_0800200_CIDR.2,
data = boruta_important_data,
family = binomial())
summary(model_interaction)
# assess if there is interaction between the different proteins
model_interaction <- glm(Gravida ~ PF3D7_0100100_CIDR.2.8 * PF3D7_0533100_DBL5 ,
data = boruta_important_data,
family = binomial())
summary(model_interaction)
random_forest_data <- az_proteins_heatmap %>%
select(Protein_ID, Ab_responses,  Study.Number, Gravida) %>%
pivot_wider(values_from = Ab_responses,
names_from = Protein_ID) %>%
select(3:700, 2) %>%
mutate(Gravida=as.factor(Gravida))
index_row <- sample(1:2,
nrow(random_forest_data),
replace = T,
prob = c(0.7,0.3))
train_data <- random_forest_data[index_row==1,]
test_data <- random_forest_data[index_row==2,]
# Make predictions on the test set
predictions <- predict(classifier, newdata = test_data)
# Make predictions on the test set
rf_predictions <- predict(classifier, newdata = test_data)
# Evaluate model performance
confusion_matrix <- table(rf_predictions, test_data$Gravida)
confusion_matrix
sum(diag(confusion_matrix))
sum(confusion_matrix)
# Evaluate accuracy of the rf model
accuracy <- sum(diag(confusion_matrix)) / sum(confusion_matrix)
accuracy
random_forest_data <- az_proteins_heatmap %>%
select(Protein_ID, Ab_responses,  Study.Number, Gravida) %>%
pivot_wider(values_from = Ab_responses,
names_from = Protein_ID) %>%
select(3:700, 2) %>%
mutate(Gravida=as.factor(Gravida))
index_row <- sample(1:2,
nrow(random_forest_data),
replace = T,
prob = c(0.6,0.4))
train_data <- random_forest_data[index_row==1,]
test_data <- random_forest_data[index_row==2,]
# Run random forest to test the data
classifier <- randomForest(Gravida ~ .,
data=train_data,
importance=T, ntree=1000)
classifier
# Make predictions on the test set
rf_predictions <- predict(classifier, newdata = test_data)
# Evaluate model performance
confusion_matrix <- table(rf_predictions, test_data$Gravida)
confusion_matrix
# Evaluate accuracy of the rf model
accuracy <- sum(diag(confusion_matrix)) / sum(confusion_matrix)
accuracy
index_row <- sample(1:2,
nrow(random_forest_data),
replace = T,
prob = c(0.7,0.3))
train_data <- random_forest_data[index_row==1,]
test_data <- random_forest_data[index_row==2,]
# Run random forest to test the data
classifier <- randomForest(Gravida ~ .,
data=train_data,
importance=T, ntree=1000)
classifier
# Make predictions on the test set
rf_predictions <- predict(classifier, newdata = test_data)
# Evaluate model performance
confusion_matrix <- table(rf_predictions, test_data$Gravida)
confusion_matrix
###############################################################################
# Random forest to identify the most important antigens
#################################################################################
# Entire dataset for Gravida 1,2,3 for random forest
set.seed(222)
random_forest_data <- az_proteins_heatmap %>%
select(Protein_ID, Ab_responses,  Study.Number, Gravida) %>%
pivot_wider(values_from = Ab_responses,
names_from = Protein_ID) %>%
select(3:700, 2) %>%
mutate(Gravida=as.factor(Gravida))
index_row <- sample(1:2,
nrow(random_forest_data),
replace = T,
prob = c(0.7,0.3))
train_data <- random_forest_data[index_row==1,]
test_data <- random_forest_data[index_row==2,]
# Run random forest to test the data
classifier <- randomForest(Gravida ~ .,
data=train_data,
importance=T, ntree=1000)
classifier
# Make predictions on the test set
rf_predictions <- predict(classifier, newdata = test_data)
# Evaluate model performance
confusion_matrix <- table(rf_predictions, test_data$Gravida)
confusion_matrix
# Evaluate accuracy of the rf model
accuracy <- sum(diag(confusion_matrix)) / sum(confusion_matrix)
accuracy
accuracy
###############################################################################
# Random forest to identify the most important antigens
#################################################################################
# Entire dataset for Gravida 1,2,3 for random forest
set.seed(222)
random_forest_data <- az_proteins_heatmap %>%
select(Protein_ID, Ab_responses,  Study.Number, Gravida) %>%
pivot_wider(values_from = Ab_responses,
names_from = Protein_ID) %>%
select(3:700, 2) %>%
mutate(Gravida=as.factor(Gravida))
index_row <- sample(1:2,
nrow(random_forest_data),
replace = T,
prob = c(0.7,0.3))
train_data <- random_forest_data[index_row==1,]
test_data <- random_forest_data[index_row==2,]
# Run random forest to test the data
classifier <- randomForest(Gravida ~ .,
data=train_data,
importance=T, ntree=1000)
classifier
# Make predictions on the test set
rf_predictions <- predict(classifier, newdata = test_data)
# Evaluate model performance
confusion_matrix <- table(rf_predictions, test_data$Gravida)
confusion_matrix
# Evaluate accuracy of the rf model
accuracy <- sum(diag(confusion_matrix)) / sum(confusion_matrix)
accuracy
#############################################################################
# Run the Boruta algorithm (Random forest wrapper)
set.seed(123)
###############################################################################
# Random forest to identify the most important antigens
#################################################################################
# Entire dataset for Gravida 1,2,3 for random forest
set.seed(222)
random_forest_data <- az_proteins_heatmap %>%
select(Protein_ID, Ab_responses,  Study.Number, Gravida) %>%
pivot_wider(values_from = Ab_responses,
names_from = Protein_ID) %>%
select(3:700, 2) %>%
mutate(Gravida=as.factor(Gravida))
index_row <- sample(1:2,
nrow(random_forest_data),
replace = T,
prob = c(0.8,0.2))
train_data <- random_forest_data[index_row==1,]
test_data <- random_forest_data[index_row==2,]
# Run random forest to test the data
classifier <- randomForest(Gravida ~ .,
data=train_data,
importance=T, ntree=1000)
classifier
# Make predictions on the test set
rf_predictions <- predict(classifier, newdata = test_data)
# Evaluate model performance
confusion_matrix <- table(rf_predictions, test_data$Gravida)
confusion_matrix
# Evaluate accuracy of the rf model
accuracy <- sum(diag(confusion_matrix)) / sum(confusion_matrix)
accuracy
###############################################################################
# Random forest to identify the most important antigens
#################################################################################
# Entire dataset for Gravida 1,2,3 for random forest
set.seed(222)
random_forest_data <- az_proteins_heatmap %>%
select(Protein_ID, Ab_responses,  Study.Number, Gravida) %>%
pivot_wider(values_from = Ab_responses,
names_from = Protein_ID) %>%
select(3:700, 2) %>%
mutate(Gravida=as.factor(Gravida))
index_row <- sample(1:2,
nrow(random_forest_data),
replace = T,
prob = c(0.65,0.35))
train_data <- random_forest_data[index_row==1,]
test_data <- random_forest_data[index_row==2,]
# Run random forest to test the data
classifier <- randomForest(Gravida ~ .,
data=train_data,
importance=T, ntree=1000)
classifier
# Make predictions on the test set
rf_predictions <- predict(classifier, newdata = test_data)
# Evaluate model performance
confusion_matrix <- table(rf_predictions, test_data$Gravida)
confusion_matrix
# Evaluate accuracy of the rf model
accuracy <- sum(diag(confusion_matrix)) / sum(confusion_matrix)
accuracy
#############################################################################
# Run the Boruta algorithm (Random forest wrapper)
set.seed(123)
random_forest_data <- az_proteins_heatmap %>%
select(Protein_ID, Ab_responses,  Study.Number, Gravida) %>%
pivot_wider(values_from = Ab_responses,
names_from = Protein_ID) %>%
select(3:700, 2) %>%
mutate(Gravida=as.factor(Gravida))
index_row <- sample(1:2,
nrow(random_forest_data),
replace = T,
prob = c(0.65,0.35))
train_data <- random_forest_data[index_row==1,]
test_data <- random_forest_data[index_row==2,]
# Run random forest to test the data
classifier <- randomForest(Gravida ~ .,
data=train_data,
importance=T, ntree=1000)
classifier
# Make predictions on the test set
rf_predictions <- predict(classifier, newdata = test_data)
# Evaluate model performance
confusion_matrix <- table(rf_predictions, test_data$Gravida)
confusion_matrix
# Evaluate accuracy of the rf model
accuracy <- sum(diag(confusion_matrix)) / sum(confusion_matrix)
accuracy
#############################################################################
# Run the Boruta algorithm (Random forest wrapper)
set.seed(123)
###############################################################################
# Random forest to identify the most important antigens
#################################################################################
# Entire dataset for Gravida 1,2,3 for random forest
set.seed(222)
random_forest_data <- az_proteins_heatmap %>%
select(Protein_ID, Ab_responses,  Study.Number, Gravida) %>%
pivot_wider(values_from = Ab_responses,
names_from = Protein_ID) %>%
select(3:700, 2) %>%
mutate(Gravida=as.factor(Gravida))
index_row <- sample(1:2,
nrow(random_forest_data),
replace = T,
prob = c(0.67,0.33))
train_data <- random_forest_data[index_row==1,]
test_data <- random_forest_data[index_row==2,]
# Run random forest to test the data
classifier <- randomForest(Gravida ~ .,
data=train_data,
importance=T, ntree=1000)
classifier
# Make predictions on the test set
rf_predictions <- predict(classifier, newdata = test_data)
# Evaluate model performance
confusion_matrix <- table(rf_predictions, test_data$Gravida)
confusion_matrix
# Evaluate accuracy of the rf model
accuracy <- sum(diag(confusion_matrix)) / sum(confusion_matrix)
accuracy
#############################################################################
# Run the Boruta algorithm (Random forest wrapper)
set.seed(123)
?randomForest
# Run random forest to test the data
classifier <- randomForest(Gravida ~ .,
data=train_data,
importance=T, ntree=1000,
do.Trace=T, cross=10)
classifier
# Make predictions on the test set
rf_predictions <- predict(classifier, newdata = test_data)
# Evaluate model performance
confusion_matrix <- table(rf_predictions, test_data$Gravida)
confusion_matrix
# Evaluate accuracy of the rf model
accuracy <- sum(diag(confusion_matrix)) / sum(confusion_matrix)
accuracy
index_row <- sample(1:2,
nrow(random_forest_data),
replace = T,
prob = c(0.7,0.3))
train_data <- random_forest_data[index_row==1,]
test_data <- random_forest_data[index_row==2,]
###############################################################################
# Random forest to identify the most important antigens
#################################################################################
# Entire dataset for Gravida 1,2,3 for random forest
set.seed(222)
random_forest_data <- az_proteins_heatmap %>%
select(Protein_ID, Ab_responses,  Study.Number, Gravida) %>%
pivot_wider(values_from = Ab_responses,
names_from = Protein_ID) %>%
select(3:700, 2) %>%
mutate(Gravida=as.factor(Gravida))
index_row <- sample(1:2,
nrow(random_forest_data),
replace = T,
prob = c(0.7,0.3))
train_data <- random_forest_data[index_row==1,]
test_data <- random_forest_data[index_row==2,]
# Run random forest to test the data
classifier <- randomForest(Gravida ~ .,
data=train_data,
importance=T, ntree=1000,
do.Trace=T, cross=10)
classifier
# Make predictions on the test set
rf_predictions <- predict(classifier, newdata = test_data)
# Evaluate model performance
confusion_matrix <- table(rf_predictions, test_data$Gravida)
confusion_matrix
# Evaluate accuracy of the rf model
accuracy <- sum(diag(confusion_matrix)) / sum(confusion_matrix)
accuracy
#############################################################################
# Run the Boruta algorithm (Random forest wrapper)
set.seed(123)
# Compute variable importance based on predicted values
importance_values <- importance(classifier, type = 1)
importance_values
importance_values <- as.data.frame(importance_values)
View(importance_values)
importance_values$protein_ID <- rownames(importance_values)
rownames(importance_values) <- NULL
View(importance_values)
importance_values %>%
ggplot()+
geom_point(aes(protein_ID, MeanDecreaseAccuracy))
importance_values %>%
arrange(MeanDecreaseAccuracy)%>%
ggplot()+
geom_point(aes(protein_ID, MeanDecreaseAccuracy))
importance_values %>%
arrange(desc(MeanDecreaseAccuracy))%>%
ggplot()+
geom_point(aes(protein_ID, MeanDecreaseAccuracy))
importance_values %>%
arrange(desc(MeanDecreaseAccuracy))
importance_values %>%
arrange(desc(MeanDecreaseAccuracy))
importance_values %>%
arrange(desc(MeanDecreaseAccuracy))%>%
ggplot()+
geom_bar(aes(protein_ID, MeanDecreaseAccuracy))
importance_values %>%
arrange(desc(MeanDecreaseAccuracy))%>%
ggplot()+
geom_bar(aes(protein_ID, MeanDecreaseAccuracy), stat = "identity")
importance_values %>%
arrange(desc(MeanDecreaseAccuracy))%>%
ggplot()+
geom_bar(aes(protein_ID, reorder(MeanDecreaseAccuracy)), stat = "identity")
importance_values %>%
arrange(desc(MeanDecreaseAccuracy))%>%
ggplot()+
geom_bar(aes(reorder(protein_ID), MeanDecreaseAccuracy), stat = "identity")
importance_values %>%
arrange(desc(MeanDecreaseAccuracy))%>%
filter(MeanDecreaseAccuracy>0)%>%
ggplot()+
geom_bar(aes(protein_ID, MeanDecreaseAccuracy), stat = "identity")
importance_values %>%
arrange(desc(MeanDecreaseAccuracy))%>%
filter(MeanDecreaseAccuracy>0)%>%
ggplot()+
geom_bar(aes( MeanDecreaseAccuracy, protein_ID), stat = "identity")
importance_values %>%
arrange(desc(MeanDecreaseAccuracy))%>%
filter(MeanDecreaseAccuracy>2)%>%
ggplot()+
geom_bar(aes( MeanDecreaseAccuracy, protein_ID), stat = "identity")
importance_values %>%
arrange(desc(MeanDecreaseAccuracy))%>%
filter(MeanDecreaseAccuracy>3)%>%
ggplot()+
geom_bar(aes( MeanDecreaseAccuracy, protein_ID), stat = "identity")
importance_values %>%
arrange(desc(MeanDecreaseAccuracy))%>%
filter(MeanDecreaseAccuracy>2)%>%
ggplot()+
geom_bar(aes( MeanDecreaseAccuracy, protein_ID), stat = "identity")
importance_values %>%
arrange(desc(MeanDecreaseAccuracy))%>%
filter(MeanDecreaseAccuracy>2)%>%
ggplot()+
geom_bar(aes( MeanDecreaseAccuracy, protein_ID), stat = "identity")
classifier$votes
classifier$votes[, "Primigravid"]
# For example, if you have predicted probabilities for the positive class (Gravida == 1), you can extract them like this:
predicted_probabilities <- classifier$votes[, "Primigravid"]
# Assuming you also have the true labels for the test set
true_labels <- test_data$Gravida
install.packages("pROC")
library(pROC)
# Compute ROC curve
roc_curve <- roc(true_labels, predicted_probabilities)
classifier
classifier$votes
###############################################################################
# Random forest to identify the most important antigens
#################################################################################
# Entire dataset for Gravida 1,2,3 for random forest
set.seed(222)
random_forest_data <- az_proteins_heatmap %>%
select(Protein_ID, Ab_responses,  Study.Number, Gravida) %>%
pivot_wider(values_from = Ab_responses,
names_from = Protein_ID) %>%
select(3:700, 2) %>%
mutate(Gravida=as.factor(Gravida))
index_row <- sample(1:2,
nrow(random_forest_data),
replace = T,
prob = c(0.7,0.3))
train_data <- random_forest_data[index_row==1,]
test_data <- random_forest_data[index_row==2,]
# Run random forest to test the data
classifier <- randomForest(Gravida ~ .,
data=train_data,
importance=T, ntree=1000,
do.Trace=T, cross=10)
classifier
classifier$votes
# Make predictions on the test set
rf_predictions <- predict(classifier, newdata = test_data)
# Evaluate model performance
confusion_matrix <- table(rf_predictions, test_data$Gravida)
confusion_matrix
# Evaluate accuracy of the rf model
accuracy <- sum(diag(confusion_matrix)) / sum(confusion_matrix)
accuracy
# Compute variable importance based on predicted values
importance_values <- importance(classifier, type = 1)
importance_values <- as.data.frame(importance_values)
importance_values$protein_ID <- rownames(importance_values)
rownames(importance_values) <- NULL
importance_values %>%
arrange(desc(MeanDecreaseAccuracy))%>%
filter(MeanDecreaseAccuracy>2)%>%
ggplot()+
geom_bar(aes( MeanDecreaseAccuracy, protein_ID), stat = "identity")
# For example, if you have predicted probabilities for the positive class (Gravida == 1), you can extract them like this:
predicted_probabilities <- classifier$votes[, "Primigravid"]
# Assuming you also have the true labels for the test set
true_labels <- train_data$Gravida
# Compute ROC curve
roc_curve <- roc(true_labels, predicted_probabilities)
# Compute ROC curve
roc_curve <- roc(true_labels, predicted_probabilities)
# Plot ROC curve
plot(roc_curve, main = "ROC Curve", col = "blue")
# Add AUC value to the plot
legend("bottomright", legend = paste("AUC =", round(auc(roc_curve), 2)), col = "blue", lwd = 1, bty = "n")
